demo_data <- demo_data %>% mutate(neighborhood = recode(Community.Reporting.Area.Name,
"Alki" = "Alki/Admiral",
"Commercial Core" = "Downtown Commercial Core",
"West Seattle Junction" = "West Seattle Junction/Genesee Hill",
"Bitter Lake Village" = "Broadview/Bitter Lake",
"Greenwood - Phinney Ridge" = "Greenwood/Phinney Ridge",
"First Hill / 12th Ave" = "First Hill",
"Westwood - Highland Park" = "Highland Park",
"Westwood - Highland Park" = "Roxhill/Westwood",
"Madison Miller" = "Miller Park",
"Mt Baker" = "Mt. Baker/North Rainier",
"North Beacon Hill" = "North Beacon Hill/Jefferson Park",
"Northgate" = "Northgate/Maple Leaf",
"Lake City" = "Olympic Hills/Victory Heights",
"Wedgwood" = "Wedgwood/View Ridge"))
View(demo_data)
head(SPL_data$study_id)
SPL2018 <- SPL_data %>% filter(study_id == "2018_Seattle_Citywide")
SPL2023 <- SPL_data %>% filter(study_id == "2023_Seattle_Citywide")
head(demo_data$ACS.Vintage)
table(demo_data$ACS.Vintage)
demo2018 <- demo_data %>% filter(ACS.Vintage == "5Y20")
demo2023 <- demo_data %>% filter(ACS.Vintage == "5Y22")
SPL2023$S_HOOD
SPL2018 <- SPL_data %>% filter(study_id == "2018_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
SPL2023 <- SPL_data %>% filter(study_id == "2023_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
demo2023 <- demo_data %>% filter(ACS.Vintage == "5Y22")
demo2018 <- demo_data %>% filter(ACS.Vintage == "5Y20")
test <- merge(SPL2018, demo2018, by=neighborhood)
test <- merge(SPL2018, demo2018, by = "neighborhood")
View(test)
demo_data_avg <- demo_data %>%
group_by(neighborhood) %>%
summarise(across("Total population":"Total Housing Units"), sum))
demo_data_avg <- demo_data %>%
group_by(neighborhood) %>%
summarise(across("Total population":"Total Housing Units"), sum)
demo_data_avg <- demo_data %>%
group_by(neighborhood) %>%
summarise(across("Total population":"Total Housing Units", sum))
demo_data_avg <- demo_data %>%
group_by(neighborhood) %>%
summarise(across('Total population':'Total Housing Units', sum))
demo_data_avg <- demo_data %>%
group_by(neighborhood) %>%
summarise(across(`Total population`:`Total Housing Units`, sum))
demo_data_avg <- demo_data %>%
group_by(neighborhood) %>%
summarise(across(Total.population:Total.Housing.Units, sum))
demo_data_avg
demo_data <- demo_data %>% mutate(neighborhood = recode(Community.Reporting.Area.Name,
"Alki" = "Alki/Admiral",
"Commercial Core" = "Downtown Commercial Core",
"West Seattle Junction" = "West Seattle Junction/Genesee Hill",
"Bitter Lake Village" = "Broadview/Bitter Lake",
"Greenwood - Phinney Ridge" = "Greenwood/Phinney Ridge",
"First Hill / 12th Ave" = "First Hill",
"Westwood - Highland Park" = "Highland Park",
"Westwood - Highland Park" = "Roxhill/Westwood",
"Madison Miller" = "Miller Park",
"Mt Baker" = "Mt. Baker/North Rainier",
"North Beacon Hill" = "North Beacon Hill/Jefferson Park",
"Northgate" = "Northgate/Maple Leaf",
"Lake City" = "Olympic Hills/Victory Heights",
"Wedgwood" = "Wedgwood/View Ridge"))
# Questions about Broadview/Bitter Lake and Pioneer Square/ID recode + Queen Anne too broad? Ravenna/Bryant
# Dropping these because there is not a suitable neighborhood to recode them into:
## Arbor Heights, Cascade/Eastlake (closest is SLU), Cedar Park/Meadowbrook, Duwamish/SODO, Central Area/Squire Park, Fauntleroy/Seaview, Green Lake, Haller Ridge, High Point, Interbay, Judkins Park, Laurelhurst/Sand Point, Licton Springs, Madrona/Leschi, Montlake/Portage Bay, North Beach/Blue Ridge, North Capitol Hill, North Delridge, Riverview, South Beacon Hill/NewHolly, Sunset Hills/Loyal Heights
# Cleaning code to fix= First Hill / 12th Ave (not broadview) and 23rd and jackson (not pinehurst)
demo_data_avg <- demo_data %>%
group_by(neighborhood) %>%
summarise(across(Total.population:Total.Housing.Units, sum))
demo_data_avg
View(demo_data_avg)
demo_data <- demo_data %>% mutate(neighborhood = recode(Community.Reporting.Area.Name,
"Alki" = "Alki/Admiral",
"Commercial Core" = "Downtown Commercial Core",
"West Seattle Junction" = "West Seattle Junction/Genesee Hill",
"Bitter Lake Village" = "Broadview/Bitter Lake",
"Greenwood - Phinney Ridge" = "Greenwood/Phinney Ridge",
"First Hill / 12th Ave" = "First Hill",
"Westwood - Highland Park" = "Highland Park",
"Westwood - Highland Park" = "Roxhill/Westwood",
"Madison Miller" = "Miller Park",
"Mt Baker" = "Mt. Baker/North Rainier",
"North Beacon Hill" = "North Beacon Hill/Jefferson Park",
"Northgate" = "Northgate/Maple Leaf",
"Lake City" = "Olympic Hills/Victory Heights",
"Wedgwood" = "Wedgwood/View Ridge"))
View(demo_data)
library(tidyverse)
library(here)
#Census data from: https://data-seattlecitygis.opendata.arcgis.com/datasets/SeattleCityGIS::selected-demographic-and-housing-estimates-dp05/about
#Census data from Seattle from 2010-2022
demo_data <- read.csv(here("data","05_SPL_Demographics.csv"))
#Clean SPL 2018 and 2023 data
SPL_data <- read.csv(here("data", "SPL_1823.csv"))
demo_data <- demo_data %>% mutate(neighborhood = recode(Community.Reporting.Area.Name,
"Alki" = "Alki/Admiral",
"Commercial Core" = "Downtown Commercial Core",
"West Seattle Junction" = "West Seattle Junction/Genesee Hill",
"Bitter Lake Village" = "Broadview/Bitter Lake",
"Greenwood - Phinney Ridge" = "Greenwood/Phinney Ridge",
"First Hill / 12th Ave" = "First Hill",
"Westwood - Highland Park" = "Highland Park",
"Westwood - Highland Park" = "Roxhill/Westwood",
"Madison Miller" = "Miller Park",
"Mt Baker" = "Mt. Baker/North Rainier",
"North Beacon Hill" = "North Beacon Hill/Jefferson Park",
"Northgate" = "Northgate/Maple Leaf",
"Lake City" = "Olympic Hills/Victory Heights",
"Wedgwood" = "Wedgwood/View Ridge"))
head(demo_data$neighborhood)
tail(demo_data$neighborhood)
table(demo_data$neighborhood)
demo_data <- demo_data %>% mutate(neighborhood = recode(Community.Reporting.Area.Name,
"Alki/Admiral" = "Alki",
"Commercial Core" = "Downtown Commercial Core",
"West Seattle Junction" = "West Seattle Junction/Genesee Hill",
"Bitter Lake Village" = "Broadview/Bitter Lake",
"Greenwood - Phinney Ridge" = "Greenwood/Phinney Ridge",
"First Hill / 12th Ave" = "First Hill",
"Westwood - Highland Park" = "Highland Park",
"Westwood - Highland Park" = "Roxhill/Westwood",
"Madison Miller" = "Miller Park",
"Mt Baker" = "Mt. Baker/North Rainier",
"North Beacon Hill" = "North Beacon Hill/Jefferson Park",
"Northgate" = "Northgate/Maple Leaf",
"Lake City" = "Olympic Hills/Victory Heights",
"Wedgwood" = "Wedgwood/View Ridge"))
table(demo_data$neighborhood)
demo_data <- demo_data %>% mutate(neighborhood = recode(Community.Reporting.Area.Name,
"Alki/Admiral" = "Alki",
"Downtown Commercial Core" = "Commercial Core",
"West Seattle Junction/Genesee Hill" = "West Seattle Junction",
"Broadview/Bitter Lake" = "Bitter Lake Village",
"Greenwood/Phinney Ridge" = "Greenwood - Phinney Ridge",
"First Hill" = "First Hill / 12th Ave",
"Highland Park" = "Westwood - Highland Park",
"Roxhill/Westwood" = "Westwood - Highland Park",
"Miller Park" = "Madison Miller",
"Mt. Baker/North Rainier" = "Mt Baker",
"North Beacon Hill/Jefferson Park" = "North Beacon Hill",
"Northgate/Maple Leaf" = "Northgate",
"Olympic Hills/Victory Heights" = "Lake City",
"Wedgwood/View Ridge" = "Wedgwood"))
table(demo_data$neighborhood)
demo_data_avg <- demo_data %>%
group_by(neighborhood) %>%
summarise(across(Total.population:Total.Housing.Units, sum))
demo_data_avg
SPL2018 <- SPL_data %>% filter(study_id == "2018_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
demo2018 <- demo_data %>% filter(ACS.Vintage == "5Y20")
SPL2023 <- SPL_data %>% filter(study_id == "2023_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
demo2023 <- demo_data %>% filter(ACS.Vintage == "5Y22")
test <- merge(SPL2018, demo2018, by = "neighborhood")
View(test)
test <- merge(SPL2018, demo2018, by = "neighborhood", all = FALSE)
View(test)
test <- distinct(merge(SPL2018, demo2018, by = "neighborhood", all = FALSE))
test <- merge(SPL2018, demo2018, by = "neighborhood", all = FALSE)
View(test)
test2 <- distinct(test, unique_staying_id), .keep_all = TRUE)
test2 <- distinct(test, unique_staying_id, .keep_all = TRUE)
View(test2)
SPL2023 <- SPL_data %>% filter(study_id == "2023_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Filtering census data to 2022 only (closest year to 2023 that is available)
demo2023 <- demo_data %>% filter(ACS.Vintage == "5Y22")
##Merging both dataframes by the neighborhood column
merged2023 <- merge(SPL2018, demo2018, by = "neighborhood", all = FALSE)
##Filtering so that there is just one row per unique_staying_id
merged2023 <- distinct(test, unique_staying_id, .keep_all = TRUE)
SPL2018 <- SPL_data %>% filter(study_id == "2018_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Filtering census data to 2020 only (closest year to 2018 that is available)
demo2018 <- demo_data %>% filter(ACS.Vintage == "5Y20")
##Merging both dataframes by the neighborhood column
merged2018 <- merge(SPL2018, demo2018, by = "neighborhood", all = FALSE)
##Filtering so that there is just one row per unique_staying_id
merged2018 <- distinct(test, unique_staying_id, .keep_all = TRUE)
# Creating one big dataframe for 2018 and 2023 data
SPL_1823_demographics <- rbind(merged2018, merged2023)
View(SPL_1823_demographics)
##Cleaning it up
SPL_1823_demographics <- SPL_1823_demographics %>% dplyr::select(neighborhood, unique_staying_id:ACS.Vintage)
getwd()
##Saving it
write.csv(SPL_1823_demographics, here("data", "SPL_1823_demographics.csv"))
library(tidyverse)
library(here)
#Census data from: https://data-seattlecitygis.opendata.arcgis.com/datasets/SeattleCityGIS::selected-demographic-and-housing-estimates-dp05/about
#Census data from Seattle from 2010-2022
demo_data <- read.csv(here("data","05_SPL_Demographics.csv"))
#Census data from: https://data-seattlecitygis.opendata.arcgis.com/datasets/SeattleCityGIS::selected-demographic-and-housing-estimates-dp05/about
#Census data from Seattle from 2010-2022
demo_data <- read.csv(here("data","05_SPL_Demographics.csv"))
#Census data from Seattle from 2010-2022
demo_data <- read.csv(here("data","05_SPL_Demographics.csv"))
#Census data from Seattle from 2010-2022
demo_data <- read.csv(here("Raw","05_SPL_Demographics.csv"))
#Census data from: https://data-seattlecitygis.opendata.arcgis.com/datasets/SeattleCityGIS::selected-demographic-and-housing-estimates-dp05/about
#Census data from Seattle from 2010-2022
demo_data <- read.csv(here("Raw","05_SPL_Demographics.csv"))
#Census data from Seattle from 2010-2022
demo_data <- read.csv(here("data/Raw","05_SPL_Demographics.csv"))
#Clean SPL 2018 and 2023 data
SPL_data <- read.csv(here("data", "SPL_1823.csv"))
table(SPL_data$location_neighborhood)
# 2018 data
##Creating a 2018 specific staying dataframe
SPL2018 <- SPL_data %>% filter(study_id == "2018_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
library(tidyverse)
library(here)
#Census data from: https://data-seattlecitygis.opendata.arcgis.com/datasets/SeattleCityGIS::selected-demographic-and-housing-estimates-dp05/about
#Census data from Seattle from 2010-2022
demo_data <- read.csv(here("data/Raw","05_SPL_Demographics.csv"))
#Clean SPL 2018 and 2023 data
SPL_data <- read.csv(here("data", "SPL_1823.csv"))
demo_data <- demo_data %>% mutate(neighborhood = recode(Community.Reporting.Area.Name,
"Alki/Admiral" = "Alki",
"Downtown Commercial Core" = "Commercial Core",
"West Seattle Junction/Genesee Hill" = "West Seattle Junction",
"Broadview/Bitter Lake" = "Bitter Lake Village",
"Greenwood/Phinney Ridge" = "Greenwood - Phinney Ridge",
"First Hill" = "First Hill / 12th Ave",
"Highland Park" = "Westwood - Highland Park",
"Roxhill/Westwood" = "Westwood - Highland Park",
"Miller Park" = "Madison Miller",
"Mt. Baker/North Rainier" = "Mt Baker",
"North Beacon Hill/Jefferson Park" = "North Beacon Hill",
"Northgate/Maple Leaf" = "Northgate",
"Olympic Hills/Victory Heights" = "Lake City",
"Wedgwood/View Ridge" = "Wedgwood"))
# Make sure all versions of QA in the other data set get the QA data from this dataset
# Questions:
## Broadview/Bitter Lake, Pioneer Square/ID, and Ravenna/Bryant recode (should I pick one or the other neighborhood to recode it into bc the location_neighborhood column in the SPL_1823 data I'm matching has these as separate entries)
## This dataset only has Queen Anne, but this is split into North and Lower in the location_neighborhood column
## Note that need to update original cleaning code to fix= First Hill / 12th Ave (not broadview) and 23rd and jackson (not pinehurst)
table(SPL_data$location_neighborhood)
demo_data_avg <- demo_data %>%
group_by(neighborhood) %>%
summarise(across(Total.population:Total.Housing.Units, sum))
# 2018 data
##Creating a 2018 specific staying dataframe
SPL2018 <- SPL_data %>% filter(study_id == "2018_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Filtering census data to 2020 only (closest year to 2018 that is available)
demo2018 <- demo_data %>% filter(ACS.Vintage == "5Y20")
##Merging both dataframes by the neighborhood column
merged2018 <- merge(SPL2018, demo2018, by = "neighborhood", all = TRUE)
demo_data_avg <- demo_data %>%
group_by(neighborhood) %>%
summarise(across(Total.population:Total.Housing.Units, sum))
# 2018 data
##Creating a 2018 specific staying dataframe
SPL2018 <- SPL_data %>% filter(study_id == "2018_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Filtering census data to 2020 only (closest year to 2018 that is available)
demo2018 <- demo_data %>% filter(ACS.Vintage == "5Y20")
##Merging both dataframes by the neighborhood column
merged2018 <- merge(SPL2018, demo2018, by = "neighborhood", all = TRUE)
##Filtering so that there is just one row per unique_staying_id
merged2018 <- distinct(test, unique_staying_id, .keep_all = TRUE)
# 2018 data
##Creating a 2018 specific staying dataframe
SPL2018 <- SPL_data %>% filter(study_id == "2018_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Filtering census data to 2020 only (closest year to 2018 that is available)
demo2018 <- demo_data %>% filter(ACS.Vintage == "5Y20")
##Merging both dataframes by the neighborhood column
merged2018 <- merge(SPL2018, demo2018, by = "neighborhood", all = TRUE)
##Filtering so that there is just one row per unique_staying_id
merged2018 <- distinct(merged2018, unique_staying_id, .keep_all = TRUE)
# 2023 data
##Creating a 2023 specific staying dataframe
SPL2023 <- SPL_data %>% filter(study_id == "2023_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Filtering census data to 2022 only (closest year to 2023 that is available)
demo2023 <- demo_data %>% filter(ACS.Vintage == "5Y22")
##Merging both dataframes by the neighborhood column
merged2023 <- merge(SPL2018, demo2018, by = "neighborhood", all = FALSE)
##Filtering so that there is just one row per unique_staying_id
merged2023 <- distinct(merged2023, unique_staying_id, .keep_all = TRUE)
# Creating one big dataframe for 2018 and 2023 data
SPL_1823_demographics <- rbind(merged2018, merged2023)
##Cleaning it up
SPL_1823_demographics <- SPL_1823_demographics %>% dplyr::select(neighborhood, unique_staying_id:ACS.Vintage)
View(SPL_1823_demographics)
# 2018 data
##Creating a 2018 specific staying dataframe
SPL2018 <- SPL_data %>% filter(study_id == "2018_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Filtering census data to 2020 only (closest year to 2018 that is available)
demo2018 <- demo_data_avg %>% filter(ACS.Vintage == "5Y20")
demo_data_avg <- demo_data %>%
group_by(neighborhood) %>%
summarise(across(Total.population:Total.Housing.Units, sum))
View(demo_data_avg)
demo_data_avg <- demo_data %>%
group_by(neighborhood) %>%
summarise(across(Total.population:Total.Housing.Units, sum))
# 2018 data
demo_data_avg$
##Creating a 2018 specific staying dataframe
SPL2018 <- SPL_data %>% filter(study_id == "2018_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Creating a 2018 specific staying dataframe
SPL2018 <- SPL_data %>% filter(study_id == "2018_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Filtering census data to 2020 only (closest year to 2018 that is available)
demo2018 <- demo_data %>% filter(ACS.Vintage == "5Y20")
demo2018_avg <- demo2018 %>% group_by(neighborhood) %>% summarise(across(Total.population:Total.Housing.Units, sum))
##Merging both dataframes by the neighborhood column
merged2018 <- merge(SPL2018, demo2018_avg, by = "neighborhood", all = TRUE)
##Merging both dataframes by the neighborhood column
merged2018 <- merge(SPL2018, demo2018_avg, by = "neighborhood", all = FALSE)
View(merged2018)
# 2023 data
##Creating a 2023 specific staying dataframe
SPL2023 <- SPL_data %>% filter(study_id == "2023_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Filtering census data to 2022 only (closest year to 2023 that is available)
demo2023 <- demo_data %>% filter(ACS.Vintage == "5Y22")
##Summing up total counts for each demo category per neighborhood
demo2023_avg <- demo2023 %>% group_by(neighborhood) %>% summarise(across(Total.population:Total.Housing.Units, sum))
##Summing up total counts for each demo category per neighborhood
demo2023_avg <- demo2023 %>% group_by(neighborhood) %>% summarise(across(Total.population:Total.Housing.Units, sum))
##Merging both dataframes by the neighborhood column
merged2023 <- merge(SPL2023, demo2023_avg, by = "neighborhood", all = FALSE)
##Filtering so that there is just one row per unique_staying_id
merged2023 <- distinct(merged2023, unique_staying_id, .keep_all = TRUE)
##Merging both dataframes by the neighborhood column
merged2018 <- merge(SPL2018, demo2018_avg, by = "neighborhood", all = TRUE)
##Filtering so that there is just one row per unique_staying_id
merged2018 <- distinct(merged2018, unique_staying_id, .keep_all = TRUE)
View(merged2018)
table(merged2018$neighborhood)
table(SPL_data$location_id)
table(SPL_data$location_neighborhood)
#Clean SPL 2018 and 2023 data
SPL_data <- read.csv(here("data", "SPL_1823.csv"))
table(SPL_data$location_neighborhood)
library(tidyverse)
library(here)
#Census data from: https://data-seattlecitygis.opendata.arcgis.com/datasets/SeattleCityGIS::selected-demographic-and-housing-estimates-dp05/about
#Census data from Seattle from 2010-2022
demo_data <- read.csv(here("data/Raw","05_SPL_Demographics.csv"))
#Clean SPL 2018 and 2023 data
SPL_data <- read.csv(here("data", "SPL_1823.csv"))
demo_data <- demo_data %>% mutate(neighborhood = recode(Community.Reporting.Area.Name,
"Alki/Admiral" = "Alki",
"Downtown Commercial Core" = "Commercial Core",
"West Seattle Junction/Genesee Hill" = "West Seattle Junction",
"Broadview/Bitter Lake" = "Bitter Lake Village",
"Greenwood/Phinney Ridge" = "Greenwood - Phinney Ridge",
"First Hill" = "First Hill / 12th Ave",
"Highland Park" = "Westwood - Highland Park",
"Roxhill/Westwood" = "Westwood - Highland Park",
"Miller Park" = "Madison Miller",
"Mt. Baker/North Rainier" = "Mt Baker",
"North Beacon Hill/Jefferson Park" = "North Beacon Hill",
"Northgate/Maple Leaf" = "Northgate",
"Olympic Hills/Victory Heights" = "Lake City",
"Wedgwood/View Ridge" = "Wedgwood",
"Queen Anne" = "Upper Queen Anne")) #Recoding QA into UQA because census dataset does not specify
# Questions:
## Broadview/Bitter Lake, Pioneer Square/ID, and Ravenna/Bryant recode (should I pick one or the other neighborhood to recode it into bc the location_neighborhood column in the SPL_1823 data I'm matching has these as separate entries)
## Note that need to update original cleaning code to fix= First Hill / 12th Ave (not broadview) and 23rd and jackson (not pinehurst)
table(SPL_data$location_neighborhood)
# 2018 data
##Creating a 2018 specific staying dataframe
SPL2018 <- SPL_data %>% filter(study_id == "2018_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Filtering census data to 2020 only (closest year to 2018 that is available)
demo2018 <- demo_data %>% filter(ACS.Vintage == "5Y20")
##Summing up total counts for each demo category per neighborhood
demo2018_avg <- demo2018 %>% group_by(neighborhood) %>% summarise(across(Total.population:Total.Housing.Units, sum))
##Merging both dataframes by the neighborhood column
merged2018 <- merge(SPL2018, demo2018_avg, by = "neighborhood", all = FALSE)
##Filtering so that there is just one row per unique_staying_id
merged2018 <- distinct(merged2018, unique_staying_id, .keep_all = TRUE)
# 2023 data
##Creating a 2023 specific staying dataframe
SPL2023 <- SPL_data %>% filter(study_id == "2023_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Filtering census data to 2022 only (closest year to 2023 that is available)
demo2023 <- demo_data %>% filter(ACS.Vintage == "5Y22")
##Summing up total counts for each demo category per neighborhood
demo2023_avg <- demo2023 %>% group_by(neighborhood) %>% summarise(across(Total.population:Total.Housing.Units, sum))
##Merging both dataframes by the neighborhood column
merged2023 <- merge(SPL2023, demo2023_avg, by = "neighborhood", all = FALSE)
##Filtering so that there is just one row per unique_staying_id
merged2023 <- distinct(merged2023, unique_staying_id, .keep_all = TRUE)
# Creating one big dataframe for 2018 and 2023 data
SPL_1823_demographics <- rbind(merged2018, merged2023)
##Cleaning it up
SPL_1823_demographics <- SPL_1823_demographics %>% dplyr::select(neighborhood, unique_staying_id:ACS.Vintage)
##Summing up total counts for each demo category per neighborhood
summarised_data <- demo2023 %>% group_by(neighborhood) %>% summarise(across(Total.population:Total.Housing.Units, sum))
demo2023_avg <- demo2023 %>% left_join(summarised_data, by = "neighborhood")
View(demo2023_avg)
##Merging both dataframes by the neighborhood column
merged2023 <- merge(SPL2023, demo2023_avg, by = "neighborhood", all = FALSE)
##Filtering so that there is just one row per unique_staying_id
merged2023 <- distinct(merged2023, unique_staying_id, .keep_all = TRUE)
# 2018 data
##Creating a 2018 specific staying dataframe
SPL2018 <- SPL_data %>% filter(study_id == "2018_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Filtering census data to 2020 only (closest year to 2018 that is available)
demo2018 <- demo_data %>% filter(ACS.Vintage == "5Y20")
##Summing up total counts for each demo category per neighborhood
demo2018_avg <- demo2018 %>% group_by(neighborhood) %>% summarise(across(Total.population:Total.Housing.Units, sum))
demo2018_avg <- demo2018 %>% left_join(summarised_data, by = "neighborhood")
##Merging both dataframes by the neighborhood column
merged2018 <- merge(SPL2018, demo2018_avg, by = "neighborhood", all = FALSE)
##Filtering so that there is just one row per unique_staying_id
merged2018 <- distinct(merged2018, unique_staying_id, .keep_all = TRUE)
# 2023 data
##Creating a 2023 specific staying dataframe
SPL2023 <- SPL_data %>% filter(study_id == "2023_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Filtering census data to 2022 only (closest year to 2023 that is available)
demo2023 <- demo_data %>% filter(ACS.Vintage == "5Y22")
##Summing up total counts for each demo category per neighborhood
summarised_data <- demo2023 %>% group_by(neighborhood) %>% summarise(across(Total.population:Total.Housing.Units, sum))
demo2023_avg <- demo2023 %>% left_join(summarised_data, by = "neighborhood")
##Merging both dataframes by the neighborhood column
merged2023 <- merge(SPL2023, demo2023_avg, by = "neighborhood", all = FALSE)
##Filtering so that there is just one row per unique_staying_id
merged2023 <- distinct(merged2023, unique_staying_id, .keep_all = TRUE)
# Creating one big dataframe for 2018 and 2023 data
SPL_1823_demographics <- rbind(merged2018, merged2023)
##Cleaning it up
SPL_1823_demographics <- SPL_1823_demographics %>% dplyr::select(neighborhood, unique_staying_id:ACS.Vintage)
SPL_1823_demographics$
# 2018 data
##Creating a 2018 specific staying dataframe
SPL2018 <- SPL_data %>% filter(study_id == "2018_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Filtering census data to 2020 only (closest year to 2018 that is available)
demo2018 <- demo_data %>% filter(ACS.Vintage == "5Y20")
##Summing up total counts for each demo category per neighborhood
demo2018_avg <- demo2018 %>% group_by(neighborhood) %>% summarise(across(Total.population:Total.Housing.Units, sum))
demo2018_avg <- demo2018 %>% left_join(summarised_data, by = "neighborhood")
##Merging both dataframes by the neighborhood column
merged2018 <- merge(SPL2018, demo2018_avg, by = "neighborhood", all = FALSE)
##Filtering so that there is just one row per unique_staying_id
merged2018 <- distinct(merged2018, unique_staying_id, .keep_all = TRUE)
# 2023 data
##Creating a 2023 specific staying dataframe
SPL2023 <- SPL_data %>% filter(study_id == "2023_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Filtering census data to 2022 only (closest year to 2023 that is available)
demo2023 <- demo_data %>% filter(ACS.Vintage == "5Y22")
##Summing up total counts for each demo category per neighborhood
summarised_data <- demo2023 %>% group_by(neighborhood) %>% summarise(across(Total.population:Total.Housing.Units, sum))
demo2023_avg <- demo2023 %>% left_join(summarised_data, by = "neighborhood")
##Merging both dataframes by the neighborhood column
merged2023 <- merge(SPL2023, demo2023_avg, by = "neighborhood", all = FALSE)
##Filtering so that there is just one row per unique_staying_id
merged2023 <- distinct(merged2023, unique_staying_id, .keep_all = TRUE)
# Creating one big dataframe for 2018 and 2023 data
SPL_1823_demographics <- rbind(merged2018, merged2023)
##Cleaning it up
SPL_1823_demographics <- SPL_1823_demographics %>% dplyr::select(neighborhood, unique_staying_id:ACS.Vintage)
View(SPL_1823_demographics)
View(demo_data)
View(SPL_1823_demographics)
table(SPL_1823_demographics$neighborhood)
##Summing up total counts for each demo category per neighborhood
summarised_data <- demo2018 %>% group_by(neighborhood) %>% summarise(across(Total.population:Total.Housing.Units, sum))
demo2018_avg <- demo2018 %>% left_join(summarised_data, by = "neighborhood")
##Summing up total counts for each demo category per neighborhood
summarised_data <- demo2018 %>% group_by(neighborhood) %>% summarise(across(Total.population:Total.Housing.Units, sum))
demo2018_avg <- demo2018 %>% left_join(summarised_data, by = "neighborhood")
table(demo2018_avg$neighborhood)
demo_data <- demo_data %>% mutate(neighborhood = recode(Community.Reporting.Area.Name,
"Alki/Admiral" = "Alki",
"Downtown Commercial Core" = "Commercial Core",
"West Seattle Junction/Genesee Hill" = "West Seattle Junction",
"Greenwood/Phinney Ridge" = "Greenwood - Phinney Ridge",
"First Hill" = "First Hill / 12th Ave",
"Highland Park" = "Westwood - Highland Park",
"Roxhill/Westwood" = "Westwood - Highland Park",
"Miller Park" = "Madison Miller",
"Mt. Baker/North Rainier" = "Mt Baker",
"North Beacon Hill/Jefferson Park" = "North Beacon Hill",
"Northgate/Maple Leaf" = "Northgate",
"Olympic Hills/Victory Heights" = "Lake City",
"Wedgwood/View Ridge" = "Wedgwood",
"Queen Anne" = "Upper Queen Anne")) #Recoding QA into UQA because census dataset does not specify
# Questions:
## Broadview/Bitter Lake, Pioneer Square/ID, and Ravenna/Bryant recode (should I pick one or the other neighborhood to recode it into bc the location_neighborhood column in the SPL_1823 data I'm matching has these as separate entries)
## Note that need to update original cleaning code to fix= First Hill / 12th Ave (not broadview) and 23rd and jackson (not pinehurst)
# 2018 data
##Creating a 2018 specific staying dataframe
SPL2018 <- SPL_data %>% filter(study_id == "2018_Seattle_Citywide") %>%
rename("neighborhood" = "location_neighborhood")
##Filtering census data to 2020 only (closest year to 2018 that is available)
demo2018 <- demo_data %>% filter(ACS.Vintage == "5Y20")
##Summing up total counts for each demo category per neighborhood
summarised_data <- demo2018 %>% group_by(neighborhood) %>% summarise(across(Total.population:Total.Housing.Units, sum))
demo2018_avg <- demo2018 %>% left_join(summarised_data, by = "neighborhood")
table(demo2018_avg$neighborhood)
View(demo2018_avg)
